
GridSearchCV  --Класс "Простой решетчатый поиск"
Поиск оптимальных значений ключевых параметров модели
>> param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'gamma': [0.001, 0.01, 0.1, 1, 10, 100]}
>> grid_search = GridSearchCV(SVC(), param_grid, cv=5)
>> grid_search.fit(X_train, y_train)

sklearn.model_selection.cross_val_score --
Оценка результатов методом "Перекрёстная 5-ти блочная проверка"
>> lr = LogisticRegression(max_iter=100_000, C=1).fit(X_train_scaled, y_train)
>> scores_train = cross_val_score(lr, X_train_scaled, y_train, cv=5)
>> scores_test = cross_val_score(lr, X_test_scaled, y_test, cv=5)

Функции, с помощью которых можно оценить неопределенность прогнозов: decision_function, predict_proba

decision_function(X_test) -- Решаущая функция
Значение показывает, насколько сильно модель уверена в том, что точка данных принадлежит «положительному» классу, в данном случае,
классу 1. Положительное значение указывает на предпочтение в пользу позиционного класса, а отрицательное значение – на предпочтение в
пользу «отрицательного» (другого) класса.

predict_proba –- Прогнозирование вероятностей
это вероятность каждого класса и часто его легче понять, чем вывод метода decision_function. Для бинарной классификации
он всегда имеет форму (n_samples, 2)
Первый элемент строки – это оценка вероятности первого класса, а второй элемент строки – это оценка вероятности второго класса.

precision_recall_curve --
Функция возвращает список значений точности и полноты для всех возможных пороговых значений (всех значений
решающей функции) в отсортированном виде

ROC-кривая -- кривая рабочей характеристики приемника
ROC-кривая позволяет рассмотреть все пороговые значения для данного классификатора, но вместо точности и полноты
она показывает долю ложно положительных примеров в сравнении с долей истинно положительных примеров

sklearn.metrics.roc_curve --
Функция вычисляет рабочии харектеристики ROC-кривой
fpr, tpr, thresholds = roc_curve(y_test, svc.decision_function(X_test))

roc_auc_score --
Функция вычисляет AUC -- площадь под ROC-кривой.
Примечание: эту реализацию можно использовать с бинарной, многоклассовой и многоуровневой классификацией,
но применяются некоторые ограничения.
svc_auc = roc_auc_score(y_test, svc.decision_function(X_test))

sklearn.metrics.confusion_matrix --
Вычислите матрицу ошибок, чтобы оценить точность классификации.
>>> from sklearn.metrics import confusion_matrix
>>> y_true = [2, 0, 2, 2, 0, 1]
>>> y_pred = [0, 0, 2, 2, 0, 2]
>>> confusion_matrix(y_true, y_pred)
array([[2, 0, 0],
       [0, 0, 1],
       [1, 0, 2]])

sklearn.metrics.accuracy_score --
В классификации с несколькими метками эта функция вычисляет точность подмножества: набор меток,
предсказанный для выборки, должен точно соответствовать соответствующему набору меток в y_true.
>> from sklearn.metrics import accuracy_score
>> y_pred = [0, 2, 1, 3]
>> y_true = [0, 1, 2, 3]
>> accuracy_score(y_true, y_pred)
>> 0.5